## I. Introduction: Establishing the Linguistics Rationale for an FWS

### A. The Convergence of Writing Pedagogy, Technology, and Linguistic Inquiry

The emergence of generative Artificial Intelligence (AI) necessitates a critical re-evaluation of fundamental concepts central to linguistic inquiry, including the nature of language, the mechanisms of meaning generation, and the location of linguistic agency. A First-Year Writing Seminar (FWS) themed "Authorship and AI" directly addresses this exigency by reframing standard pedagogical goals—such as rhetorical awareness, critical analysis, and ethical engagement—through the rigorous frameworks provided by Theoretical Linguistics, Computational Linguistics, and the Philosophy of Language. The proposed curriculum transforms the study of writing from a purely compositional skill into an empirical and philosophical problem demanding linguistic expertise.

### B. Defining the Interdisciplinary Space: Authorship, Integrity, and Artificial Intelligence

The core of the proposed FWS resides in the interdisciplinary space defined by large language models (LLMs) and their role in text creation. The field of Computational Linguistics (CL) has undergone several major directional shifts—from information theory to formal language theory, and currently to the age of deep neural networks and applied statistics—all revolving around the mechanisms by which language is processed and generated.^1^ This seminar places students at the center of the current revolution, exploring the constellation of ideas surrounding authorship, academic integrity, and AI assistance by studying the inherent linguistic capabilities and limitations of these technologies.

### C. Rationale for Curricular Placement within a Linguistics Department

The justification for situating this FWS within a linguistics context rests on its direct engagement with the field’s most pressing theoretical and empirical challenges. While the instructor’s specialization is in TESOL and Computer-Assisted Language Learning (CALL), the course is structured to leverage these applied areas as laboratories for investigating advanced computational and theoretical linguistic concepts. For instance, analyzing how LLMs automatically enhance the linguistic complexity of Second Language (L2) writing is not merely a pedagogical concern; it is a direct empirical test of the models’ capacity for linguistic feature generation and a complex problem of competence assessment.^2^ The course provides face validity by translating applied concerns (like academic writing quality) into methodologically sound linguistic analysis projects, such as employing advanced CL techniques to analyze language patterns.^4^

## II. Philosophical Foundations of Authorship and Meaning

This section anchors the FWS in core linguistic theory by examining the debates surrounding LLMs and the nature of meaning, agency, and reference.

### A. The Competence-Performance Distinction Revisited (Chomsky Framework)

The historical challenge presented by LLMs offers a timely context for revisiting Noam Chomsky's foundational distinction between linguistic competence (the internalized, abstract knowledge of language) and linguistic performance (the actual use of language in concrete situations). The remarkable success of LLMs is often presented as evidence that high linguistic performance can be achieved without the necessity of genuine underlying competence.

The central mechanism enabling this performance is _distributional semantics_.^5^ Proponents of this view argue that the vast majority of "meaning" can be inferred solely from the relational structure of the text, based on the frequency of use of particular language elements.^5^ The LLM’s mechanism, which generates responses by calculating the most probable next word in a sequence based on its corpus, thus challenges the need for explicit, innate linguistic mechanisms typically associated with competence.

The FWS can use this theoretical conflict as its core analytical frame. Students analyze AI-generated text as a maximization of statistical probability—a demonstration of extreme linguistic _performance_—and contrast it with human writing, which reflects underlying _competence_ tied to non-linguistic intentions and consciousness.^7^ While LLMs achieve impressive imitation of human writing behavior, their capabilities are fundamentally limited by their objective (imitation) and their lack of conscious comprehension.^8^ Analyzing specific limitations, such as failures in unconstrained natural language reasoning ^9^ or generalizability ^10^, offers empirical case studies that demonstrate the systemic boundaries of a purely performance-based language model. The seminar functions, therefore, as a practical laboratory for testing philosophical claims about language structure, allowing students to determine whether meaning is an emergent statistical property or if subtle, ungrounded errors reveal the absence of genuine human-like competence.

### B. Meaning, Reference, and Intentionality: The Symbol Grounding Problem

The discussion of authorship and integrity moves beyond ethical regulations to interrogate the _integrity of meaning_ itself, anchoring the course firmly in the Philosophy of Language.

A fundamental concept is the distinction between _reference_ and _meaning_.^8^ _Reference_ pertains to the relationship between content words (e.g., "cat") and the specific entities they denote in the physical world (denotation). _Meaning_, conversely, applies to complex structures like propositions ("The cat is on the mat"), which convey ideas, assertions, and truth-values.^8^

LLMs are fundamentally limited by the Symbol Grounding Problem.^11^ Because they are trained exclusively on text and lack self-awareness, consciousness, or sensory experiences, they cannot link symbols (words) to the real world.^8^ Their processing relies on statistical correlation, not experiential context. Students in the FWS analyze LLM "hallucinations" or logical inconsistencies—where syntactically plausible text fails referentially—not as mere software malfunctions, but as symptomatic failures of grounding, directly illustrating the theoretical difference between statistically accurate syntax and referentially anchored semantic meaning.^8^

This grounding deficit is intrinsically tied to _intentionality_—the mind's directedness toward objects—which is debated as a precondition for genuine linguistic meaning.^13^ This philosophical context transforms the question of "Who is the author?" into the critical linguistic inquiry: "Which entity possesses the original intentionality and genuine reference behind this text?".^13^

### C. Speech Act Theory and AI Communication

Speech Act Theory, developed by Austin and Searle, offers the necessary framework to analyze the pragmatics of human-AI collaboration. A speech act is something that performs an action through expression, traditionally broken down into locutionary, illocutionary, and perlocutionary acts.^14^

The proposed course investigates where the linguistic agency resides in human-AI co-writing. While the LLM performs the _locutionary act_ (the utterance of a sequence of words), the human user, through their prompt, executes the _illocutionary act_ (the request, the argument, the assertion).^14^ This framework directly relates to academic accountability.^16^ Students analyze whether the _felicity conditions_ (the conditions under which a speech act is successful) for a piece of academic writing (e.g., an assertion of fact) rest entirely on the human author’s intent and subsequent verification, rather than the statistically derived text output. Applying these philosophical theories allows students to understand how LLMs mimic human processes of language understanding and communication.^15^

Table 1 provides a summary of the core philosophical justification for the curriculum:

Table 1: Philosophical Justification Mapping

| **Core Linguistics Debate** | **Key Question for Authorship & AI FWS** | **Linguistic Subfield Connection** | **Supporting Scholarly Tradition** |
| --- | --- | --- | --- |
| Competence vs. Performance | Can language success be achieved purely through distributional probability without genuine human mechanism? | Theoretical Linguistics, Psycholinguistics | Chomsky's Distinction, Distributional Semantics [5, 10] |
| Symbol Grounding Problem | How does the lack of experiential context limit AI's capacity for meaning, reference, and truth-telling? | Philosophy of Language, Cognitive Science | Russell, Frege, Intentionality Debate [8, 17] |
| Illocutionary Force | When a text is co-written, where does the authorial agency and rhetorical intent reside? | Pragmatics, Philosophy of Language | Austin/Searle Speech Act Theory ^14^ |

## III. Computational Linguistics and the Stylometrics of AI-Textuality

The course satisfies the need for empirical rigor by incorporating methodologies from Computational Linguistics (CL) and stylometry, providing students with quantifiable tools for critical rhetorical analysis.

### A. The Linguistic Fingerprint of Generative AI

The FWS justifies its inclusion in CL by studying the systematic, quantifiable differences between texts generated by humans and those generated by machines. LLM-generated text possesses a predictable linguistic fingerprint. Research indicates that AI output often defaults to a highly formal and impersonal style, characterized by the increased frequency of nouns, determiners, and adpositions, while exhibiting a lower reliance on modifiers like adjectives and adverbs.^18^Furthermore, AI text frequently displays lower lexical diversity, smaller vocabulary size, and increased textual repetition.^18^

These differences are quantifiable using metrics such as lexical density (the ratio of content-carrying words—nouns, verbs, adjectives, adverbs—to total words) and syntactic complexity (the number of clauses relative to total words).^19^ A higher lexical density, for example, typically signals greater textual complexity.

Advanced analysis using extensive linguistic feature sets, such as Douglas Biber's tagset of 66 categories, reveals precise stylistic divergences, particularly within academic genres like abstracts.^20^ LLM outputs demonstrate a higher usage of objective language, including more numbers, symbols, and auxiliaries.^21^ Key indicators of this homogenized academic voice include increased use of nominalizations (nouns derived from verbs or adjectives), agentless passive voice, and specific patterns of hedging phrases.^20^ When students rely on LLMs, they are adopting a statistically optimized, high-register, "objective" academic voice that often lacks individual "authorial presence".^4^ This diffusion of style is not merely an aesthetic concern but represents a critical linguistic phenomenon: the tendency toward homogenization of digital academic discourse mediated by powerful statistical models.

### B. Computational Approaches to Authorship and Collaboration

The seminar utilizes computational techniques to move beyond basic concepts of plagiarism detection toward the sophisticated analysis of _blended authorship_.

The curriculum can introduce students to the foundational principles of computational detection, situating the discussion within the history of CL.^1^ This involves comparing the efficacy and limitations of traditional methods, such as n-gram models, against modern neural techniques, like authorship embeddings (e.g., LUAR).^22^ N-gram models, which analyze frequent sequential patterns in text, have historically served as robust baselines for detection, while neural embeddings capture a richer diversity of stylistic features suitable for both detection and attribution.^22^

A significant challenge for these models is the rise of _human-AI co-written text_, where humans edit LLM outputs.^22^Research shows that existing models struggle to classify these blended texts, though n-gram based models are often more robust for authorship verification tasks.^22^ The analysis suggests that human intervention diffuses the distinctive AI "fingerprint," creating a stylistic "middle ground." The FWS uses this empirical observation as a generative challenge, asking students to analyze how their own interventions—editing, prompting, and refinement—alter the computational signature of the text, thereby providing deep metacognitive insight into the creation and detection of authorial voice.

Table 2 details the stylistic analysis framework that connects linguistic features to rhetorical implications.

Table 2: Stylistic Analysis Framework (Biber's Features Applied)

| **Linguistic Feature (Derived from Biber's Tagset)** | **Observed AI Trend** | **Rhetorical/FWS Implication** | **Linguistic Subfield** |
| --- | --- | --- | --- |
| Lexical Diversity/Vocabulary Size | Lower diversity, increased repetition [18, 19] | Indication of generic, uncritical language; lack of personalized voice. | Corpus/Computational Linguistics |
| Formal/Impersonal Style | Increased nouns, determiners, adpositions; fewer adjectives/adverbs ^18^ | Adoption of an overly rigid academic register; analysis of audience appropriateness. | Stylometry, Sociolinguistics |
| Syntactic Complexity Metrics | Increased use of nominalizations, auxiliary verbs; agentless passive voice [20, 21] | Illusion of objectivity or authority; critical analysis of rhetorical hedging and syntactic choices. | Computational Linguistics, Rhetoric |

## IV. Sociolinguistics, Identity, and the Digital Discourse Community

Beyond philosophical debates and computational metrics, the course draws on Sociolinguistics and Cognitive Science to frame AI as a potent language-shaping social and cognitive force, offering a critical lens for examining power, identity, and the structure of academic discourse.

### A. AI-Textuality and Sociocultural Mediation (Vygotsky, Bakhtin)

The course leverages Sociocultural Theory (SCT)—a framework central to applied linguistics and SLA—to analyze AI not merely as a tool but as a _cultural artifact_ that mediates cognitive activity. SCT, derived from Vygotsky, posits that human mental activity is shaped by our culturally constructed symbolic artifacts, with language serving as the primary learning tool.

This provides a rigorous sociolinguistic foundation for expanding Bakhtin's theory of intertextuality into "AI-textuality".^23^ AI-textuality defines meaning-making as a dynamic, dialogic process where generative AI acts as a _non-human participant_.^23^ The human user’s prompt is a textualization of their intent, and the LLM’s response is generated through computational processing of vast intertextual probabilities.^23^ The seminar can thus analyze the interaction as a form of _socially mediated learning_, asking how the LLM, acting as a powerful symbolic tool, influences the internalization of new linguistic knowledge and shapes the student's _Zone of Proximal Development_ (ZPD) in writing. The course investigates whether LLM assistance constitutes genuine cognitive mediation or merely a form of high-level performance imitation.

### B. Distributed Language and Decentralized Authorship

To satisfy the cognitive science component, the FWS frames human-AI co-writing within the tradition of **Distributed Cognition** or **Distributed Language** theory. This approach rejects the idea that authorship is confined to a single, individual mind. Instead, it conceptualizes meaning as negotiated, transformed, and _distributed_ across the human mind (intentionality, reference, rhetorical purpose) and the technological artifact (the LLM's computational architecture).

The course investigates how the authorial role is "decentralised and scattered in space and time" in telematic discourse. Students analyze their co-writing sessions to determine how the LLM's vast parameter space—which exhibits "emergent skill patterns" reminiscent of distributed cognitive organization—handles specific linguistic tasks like statistical generation and stylistic modification. This analysis directly engages with cognitive science debates over whether LLMs provide insight into human language understanding, recognizing that while the output may be functionally similar to human writing, the underlying mechanisms are profoundly different.^7^

### C. Socioindexicality and AI Power

AI’s functional role in generating and moderating digital language places it as a central social structure that directs discourse and culture.^24^ The process of human feedback (alignment and super-alignment) actively polices the output of models to ensure they produce "recognizable genres".^24^

This system warrants sociolinguistic attention because LLMs, by favoring statistically optimal features (e.g., high formality, objective language, and specific grammatical structures identified by Biber's features ^20^), effectively become _normative gatekeepers_ of academic discourse. Reliance on AI may subtly reinforce existing linguistic biases (such as reported sexist biases in some LLMs ^21^) and promote a homogeneous standard of "good" academic writing, thereby limiting linguistic innovation and individual voice—a critical sociolinguistic concern.

Furthermore, research indicates that interactive conversational AI has the potential to influence human linguistic patterns through mechanisms like linguistic accommodation and acoustic-prosodic entrainment.^25^ While evidence focuses on voice interfaces, the principle applies to written text: persistent exposure to a statistically optimized, formal LLM style may subtly shape users' own lexical and stylistic choices, impacting their self-identification and _authorial presence_.^4^ The FWS course is thus positioned to analyze the power dynamics inherent in this technological mediation, exploring how AI systems enforce specific genre and register expectations within the digital discourse community.

## V. Curricular Blueprint: Integrating Linguistic Theory and FWS Goals

The following structure demonstrates how theoretical justifications translate directly into practical, high-impact FWS modules, ensuring the course objectives are met through a uniquely linguistic and cognitive lens.

### A. Reframing Prompt Engineering as Rhetorical and Linguistic Analysis

Prompt Engineering (PE) is not positioned as a technical trick but as a sophisticated linguistic exercise in metacognitive awareness and rhetorical control.^26^ PE requires students to craft specific, detailed instructions—a process sometimes called "coding in English".^26^

The FWS curriculum teaches students to analyze the linguistic and computational limitations of the LLM and to refine their prompts using sophisticated rhetorical knowledge (e.g., specifying desired persona, tone, audience, and genre constraints).^26^ This process links prompt design directly to the frameworks of rhetorical, media, and communication science ^28^, compelling students to achieve metacognitive linguistic awareness by actively analyzing the variables that determine the quality of the linguistic output. The act of prompting is thus studied as the initiation of the _illocutionary act_within the human-AI interaction.

### B. Focus on L2 Writing and Linguistic Complexity (Connecting to TESOL/CALL)

The instructor’s background in TESOL and CALL provides an empirical focus for the course. Instead of focusing on instructional assistance, the FWS uses LLMs as objects of linguistic study.

LLMs have been shown to enhance lexical and syntactic features in L2 writing by favoring "generative rewrites".^3^ The course involves an empirical analysis where students use LLMs to revise their written work and subsequently quantify the linguistic changes using Computational Linguistics metrics (e.g., complexity indices).^3^ The goal is to determine whether these revisions genuinely improve fluency, or if they risk _altering nuance_ or merely _inflating perceived proficiency_ by applying statistically common but uncritical language.^3^ This empirical approach provides evidence that the course validates its status as a critical linguistic project testing hypotheses about automated linguistic feature manipulation.

### C. Sample Module Descriptions and Assessment Strategies

The FWS is structured around three core, linguistically-justified modules:

1.  **Module 1: The Semantics of Hallucination (Philosophical/Theoretical Focus).**
    
    -   _Assignment:_ Students prompt an LLM to generate complex factual or argumentative text and then systematically analyze its output for factual errors (hallucinations). These errors are then analyzed not as simple mistakes, but as failures of semantic grounding and referential accuracy.^8^
        
    -   _Assessment:_ Analytical Essay deconstructing AI hallucinations as systematic failures of the Symbol Grounding Problem, based on readings related to Frege, Russell, and intentionality.
        
2.  **Module 2: Decoding the AI Voice (Computational/Stylistic Focus).**
    
    -   _Assignment:_ Students compile a small corpus of their own writing, AI-generated text, and human-AI co-written text within a specific academic genre (e.g., argumentative essay). They then apply computational linguistic analysis tools (e.g., metrics for lexical density, nominalizations, and hedging features, based on Biber’s tagset ^19^) to measure stylistic differences.
        
    -   _Assessment:_ Comparative Stylistic Analysis: An empirical report detailing the quantified linguistic differences between the three text sources and a metacognitive essay analyzing the rhetorical effect of the AI's statistically derived style.
        
3.  **Module 3: The Distributed Author (Pragmatic/Sociocognitive Focus).**
    
    -   _Assignment:_ Students engage in a highly structured collaborative writing task with an LLM, documenting every prompt and subsequent response. They apply Speech Act Theory and the Distributed Cognition framework to determine where the _illocutionary act_ resides, assessing how the division of labor impacts accountability and ownership.
        
    -   _Assessment:_ Reflective Journal and Presentation: A detailed rationale and analysis of iterative prompt refinement, connecting rhetorical strategies to pragmatic and cognitive outcomes.
        

### D. Academic Integrity and Disclosure: A Philosophical Problem

The course treats university policies on academic integrity as philosophical and linguistic claims to be interrogated, rather than rules to be enforced.^16^ The definition of "authorship" is discussed as encompassing not just the act of writing, but also ownership, accountability, and the integrity of the underlying ideas.^4^ The debate over documenting and disclosing AI use ^16^ forces students to draw precise linguistic and philosophical boundaries between their cognitive contribution and the model’s statistical output.

Table 3 synthesizes the curricular elements with core FWS goals and linguistic justification.

Table 3: Curricular Synthesis and Learning Outcomes

| **Course Module/Theme** | **Core FWS Learning Goal Addressed** | **Linguistic Justification/Concepts** | **Assessment Strategy** |
| --- | --- | --- | --- |
| The Grounding Challenge | Critical Evaluation of Source Authority | Reference vs. Meaning, Symbol Grounding Problem [8, 11] | Analytical Essay: Deconstruction of AI Hallucinations as Grounding Failure. |
| The Rhetoric of the Prompt | Rhetorical Awareness, Genre Knowledge | Prompt Engineering as Complex Rhetorical Act, Intentionality [13, 26] | Reflective Journal/Presentation: Rationale and analysis of iterative prompt refinement. |
| The Distributed Author | Understanding Genre and Audience Adaptation | Distributed Cognition, Sociocultural Mediation, AI-Textuality | Comparative Stylistic Analysis: Empirical report detailing linguistic differences between human and co-written text. |

## VI. Conclusion and Recommendation

The proposed First-Year Writing Seminar, "Authorship and AI," offers a robust, multi-layered justification for its placement within a Linguistics Department. The course moves beyond a superficial exploration of technology to engage with the field's most active theoretical and empirical areas: the challenge to Chomskyan competence posed by distributional semantics, the philosophical dilemma of the Symbol Grounding Problem and intentionality, and the sociolinguistic impact of AI in normalizing and policing academic discourse.

Crucially, the curriculum now integrates core concepts from your specialization—Sociocultural Theory (SCT) and Distributed Cognition—to frame LLMs as powerful symbolic tools that mediate writing and decentralize the authorial role. By employing methodologies drawn from Computational Linguistics, such as stylometry and feature analysis (e.g., utilizing Biber’s framework), the FWS provides students with empirically rigorous tools to analyze the rhetorical, stylistic, and structural characteristics of machine-generated text. This structure transforms the instructor's background in applied linguistics (TESOL/CALL) into a methodological strength, positioning the L2 writing context as a critical empirical case study for evaluating AI’s linguistic effects.

The seminar is structured to provide clear, actionable insights into how LLMs, functioning as statistical models of language, risk creating a homogenized, statistically acceptable "academic voice" that may compromise individual authorial presence and mask underlying philosophical deficits in meaning and reference. This course is not merely "close enough" to the departmental mandate; it is a vital and timely inquiry that positions the Linguistics Department at the forefront of the academic discourse on the fundamental nature of language generation and human communication in the digital age.