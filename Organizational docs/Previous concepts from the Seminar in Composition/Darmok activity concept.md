## Activity: The "Darmok" Problem
### ðŸ‘½ Authorship, Intent, and Mediation

**Concept:** A multi-part "rug pull" activity. It uses the sci-fi dream of a "Universal Translator" as a setup, the *Star Trek* episode "Darmok" as the "problem," and connects both to the core course theme: GenAI as a mediating entity that can *perform* language but cannot *understand* or *possess* intent.

**Core Theories:**
* **Linguistic Competence:** Your internal, ideal knowledge; your *intent*.
* **Linguistic Performance:** The messy, real-world output; the *words*.
* **Mediating Entity:** A "go-between" (like an editor, a translator, or an AI) that regenerates a "performance," decoupling it from the original "competence."

---

### Phase 1: The Promise of the Tool (The Setup)

* **Activity:** Show a brief clip of a modern, real-world translation tool (e.g., Apple's Live Translation for AirPods, Google Translate).
* **Discussion Prompt:**
    > "The 'Universal Translator' is no longer just sci-fi. What is the *promise* of a tool like this? How does it appear to perfectly solve the gap between what a user *wants to say* (Competence/Intent) and what they can *actually say* (Performance)?"

---

### Phase 2: The "Darmok" Problem (The Rug Pull)

* **Activity:** Show a 3-4 minute clip from the *Star Trek: TNG* episode "Darmok," where the Universal Translator is *working perfectly* but communication is failing completely.
* **Discussion Prompt:**
    > "In this clip, the tool did its job. It translated every word of Dathon's 'Performance' ('Darmok and Jalad at Tanagra') perfectly.
    >
    > 1.  Why did communication *fail*?
    > 2.  What 'gap' did the Universal Translator fail to bridge? What was the *real* 'language' Dathon was speaking, and why couldn't the tool understand his *intent*?"

---

### Phase 3: The Synthesis (The "Big Idea")

* **Key Insight to Share:** The "language" was a shared cultural context of metaphors (the stories). The tool had no access to this "competence"; it could only translate the "performance." The solution wasn't a *better tool*; it was two people slowly, painfully building *shared human context*.
* **Connection to GenAI:**
    > GenAI *is* our "Darmok" Translator. It is a tool that is **brilliant at "Performance"** (producing fluent, grammatically plausible "AI slop") but has **zero "Competence"** (it has no intent, no understanding, no "stories" or "Darmoks" of its own).
* **Connection to Sojourner Truth:**
    > This is the same problem as Sojourner Truth's white editor. Both the editor and the AI are "mediating entities" that replace the author's true "voice" (their *intent*) with a new "performance" that fits an *external* set of expectations (a Southern vernacular, a statistical norm).
* **Final Discussion Prompt:**
    > "Based on the 'Darmok' problem, what is the *real* risk of outsourcing our writing and thinking to Generative AI? What happens to *our* 'intentionality' when we let a tool that *only* understands 'Performance' speak for us?"
